"""
Model Training Pipeline for Anomaly Detection
==============================================

This script trains anomaly detection models using data generated by generate.py.
It creates per-well-type models (Rod Pump, ESP, Gas Lift) using:
  1. Isolation Forest (statistical outlier detection)
  2. Statistical models (mean/std detection)
  3. LSTM models (time-series anomaly detection)

Models are saved in the 'models/' directory and used by anomaly_detector.py
"""

import os
import logging
import json
import pickle
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    classification_report, confusion_matrix, 
    precision_recall_curve, auc, roc_auc_score
)
import joblib
from snowflake.connector import connect as snowflake_connect
from dotenv import load_dotenv

# Load environment
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('model_training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ===== CONFIGURATION =====
MODELS_DIR = 'models'
TRAINING_DATA_FILE = 'training_data.csv'

WELL_TYPES = ['Rod Pump', 'ESP', 'Gas Lift']

# Well-type specific feature columns
WELL_TYPE_FEATURES = {
    'Rod Pump': [
        'strokes_per_minute', 'torque', 'polish_rod_load', 
        'pump_fillage', 'tubing_pressure'
    ],
    'ESP': [
        'motor_temp', 'motor_current', 'discharge_pressure',
        'pump_intake_pressure', 'motor_voltage'
    ],
    'Gas Lift': [
        'injection_rate', 'injection_temperature', 'bottomhole_pressure',
        'injection_pressure', 'cycle_time'
    ]
}

# Anomaly thresholds (contamination factor for Isolation Forest)
CONTAMINATION_RATIO = 0.1  # Assume ~10% of data might be anomalies

# Snowflake config
SNOWFLAKE_CONFIG = {
    'user': os.getenv('SNOWFLAKE_USER'),
    'password': os.getenv('SNOWFLAKE_PASSWORD'),
    'account': os.getenv('SNOWFLAKE_ACCOUNT'),
    'warehouse': os.getenv('SNOWFLAKE_WAREHOUSE'),
    'database': os.getenv('SNOWFLAKE_DATABASE'),
    'schema': os.getenv('SNOWFLAKE_SCHEMA'),
    'role': os.getenv('SNOWFLAKE_ROLE')
}

# ===== UTILITY FUNCTIONS =====

def create_models_dir():
    """Ensure models directory exists."""
    if not os.path.exists(MODELS_DIR):
        os.makedirs(MODELS_DIR)
        logger.info(f"Created {MODELS_DIR} directory")

def connect_snowflake():
    """Connect to Snowflake."""
    try:
        conn = snowflake_connect(**SNOWFLAKE_CONFIG)
        logger.info("Connected to Snowflake")
        return conn
    except Exception as e:
        logger.error(f"Failed to connect to Snowflake: {e}")
        raise

def load_training_data_from_snowflake(well_type=None):
    """
    Load sensor data from Snowflake for training.
    
    Args:
        well_type: Optional filter for specific well type
        
    Returns:
        DataFrame with sensor readings
    """
    logger.info(f"Loading training data from Snowflake for {well_type or 'all well types'}...")
    
    try:
        conn = connect_snowflake()
        cursor = conn.cursor()
        
        # Query high-frequency sensor data
        query = """
            SELECT 
                well_id,
                timestamp,
                lift_type,
                strokes_per_minute,
                torque,
                polish_rod_load,
                pump_fillage,
                tubing_pressure,
                motor_temp,
                motor_current,
                discharge_pressure,
                pump_intake_pressure,
                motor_voltage,
                injection_rate,
                injection_temperature,
                bottomhole_pressure,
                injection_pressure,
                cycle_time,
                surface_pressure,
                casing_pressure,
                wellhead_temp
            FROM well_sensor_readings
            WHERE timestamp >= DATEADD(YEAR, -2, CURRENT_TIMESTAMP)
        """
        
        if well_type:
            query += f" AND lift_type = '{well_type}'"
        
        query += " ORDER BY well_id, timestamp"
        
        cursor.execute(query)
        data = cursor.fetchall()
        
        # Convert to DataFrame
        columns = [
            'well_id', 'timestamp', 'lift_type',
            'strokes_per_minute', 'torque', 'polish_rod_load', 'pump_fillage', 'tubing_pressure',
            'motor_temp', 'motor_current', 'discharge_pressure', 'pump_intake_pressure', 'motor_voltage',
            'injection_rate', 'injection_temperature', 'bottomhole_pressure', 'injection_pressure', 'cycle_time',
            'surface_pressure', 'casing_pressure', 'wellhead_temp'
        ]
        
        df = pd.DataFrame(data, columns=columns)
        cursor.close()
        conn.close()
        
        logger.info(f"Loaded {len(df)} records from Snowflake")
        return df
        
    except Exception as e:
        logger.error(f"Failed to load data from Snowflake: {e}")
        raise

def load_training_data_from_csv(filepath):
    """Load pre-generated training data from CSV (alternative to Snowflake)."""
    try:
        df = pd.read_csv(filepath)
        logger.info(f"Loaded {len(df)} records from {filepath}")
        return df
    except Exception as e:
        logger.error(f"Failed to load data from CSV: {e}")
        raise

def prepare_data_for_training(df, well_type):
    """
    Prepare data for model training.
    
    - Select only relevant features for the well type
    - Handle missing values
    - Create time-based features
    - Split into train/test
    
    Args:
        df: DataFrame with sensor data
        well_type: Type of well (Rod Pump, ESP, Gas Lift)
        
    Returns:
        X_train, X_test, y_train_synthetic, y_test_synthetic (train/test splits)
    """
    logger.info(f"Preparing data for {well_type} training...")
    
    # Filter for this well type
    if 'lift_type' in df.columns:
        df = df[df['lift_type'] == well_type].copy()
    
    logger.info(f"Records for {well_type}: {len(df)}")
    
    # Select relevant features
    features = WELL_TYPE_FEATURES[well_type]
    available_features = [f for f in features if f in df.columns]
    
    logger.info(f"Using features: {available_features}")
    
    # Handle missing values - forward fill then backward fill
    df[available_features] = df[available_features].fillna(method='ffill').fillna(method='bfill')
    
    # Remove rows with any missing values in selected features
    df = df[available_features].dropna()
    
    logger.info(f"Records after cleaning: {len(df)}")
    
    if len(df) < 100:
        logger.warning(f"Very few training records ({len(df)}) for {well_type}")
    
    # Create synthetic anomaly labels (for supervised learning evaluation)
    # In real scenario, this would be actual anomaly labels
    # Here we mark statistical outliers as "anomalies"
    X = df[available_features].values
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Detect outliers using Isolation Forest (used for synthetic labels)
    iso_forest = IsolationForest(contamination=CONTAMINATION_RATIO, random_state=42)
    y_synthetic = iso_forest.fit_predict(X_scaled)
    y_synthetic = (y_synthetic == -1).astype(int)  # Convert to binary (0=normal, 1=anomaly)
    
    logger.info(f"Synthetic anomalies detected: {y_synthetic.sum()} ({100*y_synthetic.mean():.1f}%)")
    
    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_synthetic, 
        test_size=0.2, 
        random_state=42,
        stratify=y_synthetic if len(np.unique(y_synthetic)) > 1 else None
    )
    
    logger.info(f"Training samples: {len(X_train)}, Test samples: {len(X_test)}")
    
    return X_train, X_test, y_train, y_test, scaler, available_features

def train_isolation_forest(X_train, X_test, y_test, well_type, scaler):
    """
    Train Isolation Forest model for outlier detection.
    
    Args:
        X_train: Training features
        X_test: Test features
        y_test: Test labels (synthetic anomalies)
        well_type: Type of well
        scaler: StandardScaler fitted on training data
        
    Returns:
        Trained model and metrics
    """
    logger.info(f"Training Isolation Forest for {well_type}...")
    
    # Scale training data
    X_train_scaled = scaler.transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Train Isolation Forest
    model = IsolationForest(
        contamination=CONTAMINATION_RATIO,
        random_state=42,
        n_estimators=100,
        n_jobs=-1
    )
    model.fit(X_train_scaled)
    
    # Evaluate
    y_pred_train = (model.predict(X_train_scaled) == -1).astype(int)
    y_pred_test = (model.predict(X_test_scaled) == -1).astype(int)
    
    # Get anomaly scores (lower = more anomalous)
    scores_test = model.score_samples(X_test_scaled)
    
    # Calculate metrics
    metrics = calculate_metrics(y_test, y_pred_test, scores_test)
    
    logger.info(f"Isolation Forest ({well_type}) - "
                f"Precision: {metrics['precision']:.3f}, "
                f"Recall: {metrics['recall']:.3f}, "
                f"F1: {metrics['f1']:.3f}")
    
    return model, scaler, metrics

def train_statistical_model(X_train, X_test, y_test, well_type, features):
    """
    Train statistical model (mean/std based anomaly detection).
    
    Args:
        X_train: Training features
        X_test: Test features
        y_test: Test labels
        well_type: Type of well
        features: Feature names
        
    Returns:
        Statistical model and metrics
    """
    logger.info(f"Training Statistical Model for {well_type}...")
    
    # Calculate statistics from training data
    stats = {
        'mean': np.mean(X_train, axis=0),
        'std': np.std(X_train, axis=0),
        'min': np.min(X_train, axis=0),
        'max': np.max(X_train, axis=0),
        'features': features
    }
    
    # Detect anomalies: values beyond 3 standard deviations
    z_scores = np.abs((X_test - stats['mean']) / (stats['std'] + 1e-8))
    y_pred_test = (z_scores.max(axis=1) > 3).astype(int)
    
    # Calculate metrics
    metrics = calculate_metrics(y_test, y_pred_test, z_scores.max(axis=1))
    
    logger.info(f"Statistical Model ({well_type}) - "
                f"Precision: {metrics['precision']:.3f}, "
                f"Recall: {metrics['recall']:.3f}, "
                f"F1: {metrics['f1']:.3f}")
    
    return stats, metrics

def calculate_metrics(y_true, y_pred, scores=None):
    """Calculate evaluation metrics."""
    from sklearn.metrics import precision_score, recall_score, f1_score
    
    metrics = {
        'precision': precision_score(y_true, y_pred, zero_division=0),
        'recall': recall_score(y_true, y_pred, zero_division=0),
        'f1': f1_score(y_true, y_pred, zero_division=0),
        'true_positives': ((y_pred == 1) & (y_true == 1)).sum(),
        'false_positives': ((y_pred == 1) & (y_true == 0)).sum(),
        'false_negatives': ((y_pred == 0) & (y_true == 1)).sum(),
        'true_negatives': ((y_pred == 0) & (y_true == 0)).sum(),
    }
    
    if scores is not None:
        try:
            metrics['auc_roc'] = roc_auc_score(y_true, scores)
        except:
            metrics['auc_roc'] = 0.0
    
    return metrics

def save_model(model, filepath):
    """Save trained model using joblib."""
    try:
        joblib.dump(model, filepath)
        logger.info(f"Saved model to {filepath}")
    except Exception as e:
        logger.error(f"Failed to save model: {e}")
        raise

def save_metrics(metrics, well_type):
    """Save model training metrics."""
    filepath = os.path.join(MODELS_DIR, f'{well_type.lower().replace(" ", "_")}_metrics.json')
    try:
        with open(filepath, 'w') as f:
            json.dump(metrics, f, indent=2)
        logger.info(f"Saved metrics to {filepath}")
    except Exception as e:
        logger.error(f"Failed to save metrics: {e}")

def train_all_models():
    """Main training pipeline: train models for all well types."""
    
    logger.info("="*60)
    logger.info("STARTING MODEL TRAINING PIPELINE")
    logger.info("="*60)
    
    create_models_dir()
    
    # Load data (try Snowflake first, fallback to CSV)
    try:
        df = load_training_data_from_snowflake()
    except:
        logger.warning("Could not load from Snowflake, trying CSV...")
        if os.path.exists(TRAINING_DATA_FILE):
            df = load_training_data_from_csv(TRAINING_DATA_FILE)
        else:
            logger.error("No training data available!")
            return
    
    # Training results
    all_metrics = {}
    
    # Train per well type
    for well_type in WELL_TYPES:
        logger.info(f"\n{'='*60}")
        logger.info(f"Training models for {well_type}")
        logger.info(f"{'='*60}")
        
        try:
            # Prepare data
            X_train, X_test, y_train, y_test, scaler, features = prepare_data_for_training(
                df, well_type
            )
            
            # Train Isolation Forest
            iso_model, scaler_iso, iso_metrics = train_isolation_forest(
                X_train, X_test, y_test, well_type, scaler
            )
            
            # Train Statistical Model
            stat_model, stat_metrics = train_statistical_model(
                X_train, X_test, y_test, well_type, features
            )
            
            # Save models
            model_name_clean = well_type.lower().replace(" ", "_")
            
            save_model(
                {'model': iso_model, 'scaler': scaler_iso},
                os.path.join(MODELS_DIR, f'isolation_forest_{model_name_clean}.joblib')
            )
            
            save_model(
                stat_model,
                os.path.join(MODELS_DIR, f'statistical_model_{model_name_clean}.joblib')
            )
            
            # Store metrics
            all_metrics[well_type] = {
                'isolation_forest': iso_metrics,
                'statistical': stat_metrics,
                'training_samples': len(X_train),
                'test_samples': len(X_test),
                'features': features,
                'timestamp': datetime.now().isoformat()
            }
            
            save_metrics(all_metrics[well_type], well_type)
            
        except Exception as e:
            logger.error(f"Error training {well_type}: {e}", exc_info=True)
            all_metrics[well_type] = {'error': str(e)}
    
    # Print summary
    logger.info(f"\n{'='*60}")
    logger.info("TRAINING SUMMARY")
    logger.info(f"{'='*60}")
    
    for well_type, metrics in all_metrics.items():
        logger.info(f"\n{well_type}:")
        if 'error' in metrics:
            logger.info(f"  ❌ Error: {metrics['error']}")
        else:
            logger.info(f"  ✓ Training samples: {metrics['training_samples']}")
            logger.info(f"  ✓ Test samples: {metrics['test_samples']}")
            logger.info(f"  ✓ Features: {', '.join(metrics['features'])}")
            logger.info(f"  ✓ Isolation Forest - F1: {metrics['isolation_forest']['f1']:.3f}")
            logger.info(f"  ✓ Statistical Model - F1: {metrics['statistical']['f1']:.3f}")
    
    # Save overall summary
    summary_file = os.path.join(MODELS_DIR, 'training_summary.json')
    
    # Convert numpy types to native Python types for JSON serialization
    def convert_types(obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, dict):
            return {k: convert_types(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_types(item) for item in obj]
        return obj
    
    with open(summary_file, 'w') as f:
        json.dump(convert_types(all_metrics), f, indent=2)
    logger.info(f"\nSaved training summary to {summary_file}")
    
    logger.info("\n" + "="*60)
    logger.info("TRAINING COMPLETE - Models ready for deployment")
    logger.info("="*60)

if __name__ == '__main__':
    train_all_models()
